# ğŸ” Lavandowski - AML Analysis Platform

![Version](https://img.shields.io/badge/version-1.0.2-blue.svg)
![Python](https://img.shields.io/badge/python-3.8+-green.svg)
![License](https://img.shields.io/badge/license-Private-red.svg)

**Lavandowski** Ã© uma plataforma avanÃ§ada de anÃ¡lise AML (Anti-Money Laundering) que utiliza inteligÃªncia artificial para detectar e analisar possÃ­veis casos de lavagem de dinheiro e atividades suspeitas em transaÃ§Ãµes financeiras.

## ğŸ“‹ Ãndice

- [ğŸ” VisÃ£o Geral](#-visÃ£o-geral)
- [ğŸ—ï¸ Arquitetura](#ï¸-arquitetura)
- [ğŸ› ï¸ Tecnologias](#ï¸-tecnologias)
- [âš™ï¸ InstalaÃ§Ã£o](#ï¸-instalaÃ§Ã£o)
- [ğŸ”§ ConfiguraÃ§Ã£o](#-configuraÃ§Ã£o)
- [ğŸ¯ Funcionalidades](#-funcionalidades)
- [ğŸ¤– Agentes de AnÃ¡lise](#-agentes-de-anÃ¡lise)
- [â° Tarefas Automatizadas](#-tarefas-automatizadas)
- [ğŸŒ API Endpoints](#-api-endpoints)
- [ğŸ“Š Monitoramento](#-monitoramento)
- [ğŸš€ Uso](#-uso)
- [ğŸ‘¥ Desenvolvimento](#-desenvolvimento)

## ğŸ” VisÃ£o Geral

O Lavandowski Ã© uma soluÃ§Ã£o completa para anÃ¡lise de compliance financeiro que combina:

- **AnÃ¡lise Automatizada por IA**: Utiliza modelos GPT-4 e o3-mini para anÃ¡lise inteligente de padrÃµes suspeitos
- **DetecÃ§Ã£o de Riscos**: Sistema de pontuaÃ§Ã£o de 1-10 para classificaÃ§Ã£o automÃ¡tica de riscos
- **MÃºltiplas Fontes de Dados**: IntegraÃ§Ã£o com BigQuery, Big Data Corp e APIs externas
- **Processamento em Tempo Real**: Interface web responsiva com anÃ¡lises instantÃ¢neas
- **Tarefas Automatizadas**: Background jobs para anÃ¡lises programadas e gestÃ£o de usuÃ¡rios
- **Compliance Integrado**: Seguindo normas BACEN e melhores prÃ¡ticas AML/CFT

### ğŸ¯ Principais Recursos

- âœ… **DetecÃ§Ã£o avanÃ§ada de padrÃµes suspeitos** em transaÃ§Ãµes
- âœ… **ClassificaÃ§Ã£o automÃ¡tica de risco** com IA
- âœ… **AnÃ¡lise de vÃ­nculos** e conexÃµes entre entidades
- âœ… **GeraÃ§Ã£o de relatÃ³rios** detalhados e exportÃ¡veis
- âœ… **IntegraÃ§Ã£o com sistemas** de compliance
- âœ… **Dashboard interativo** com mÃ©tricas em tempo real
- âœ… **Processamento assÃ­ncrono** para alta performance
- âœ… **Cache inteligente** com Redis para otimizaÃ§Ã£o

## ğŸ—ï¸ Arquitetura

O sistema Ã© composto por mÃºltiplas camadas e componentes especializados:

### ğŸ“¦ Componentes Principais

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚   API Layer     â”‚    â”‚   Background    â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Streamlit     â”‚â—„â”€â”€â–ºâ”‚ â€¢ Flask API     â”‚â—„â”€â”€â–ºâ”‚ â€¢ Celery        â”‚
â”‚ â€¢ Dashboard     â”‚    â”‚ â€¢ REST Routes   â”‚    â”‚ â€¢ Redis Queue   â”‚
â”‚ â€¢ Analytics     â”‚    â”‚ â€¢ Auth Middlewareâ”‚    â”‚ â€¢ Scheduled Jobsâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚              Core Engine                      â”‚
         â”‚                                              â”‚
         â”‚ â€¢ Alert Analyser    â€¢ Sanctions Analyser    â”‚
         â”‚ â€¢ GPT Integration   â€¢ Risk Scoring          â”‚
         â”‚ â€¢ Report Generator  â€¢ Decision Engine       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚              Data Layer                       â”‚
         â”‚                                              â”‚
         â”‚ â€¢ BigQuery         â€¢ Big Data Corp           â”‚
         â”‚ â€¢ Redis Cache      â€¢ External APIs           â”‚
         â”‚ â€¢ Optimized Queries â€¢ Performance Monitoring â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”„ Fluxo de Dados

1. **IngestÃ£o**: Dados coletados de mÃºltiplas fontes (BigQuery, APIs externas)
2. **Processamento**: AnÃ¡lise por agentes especializados usando IA
3. **ClassificaÃ§Ã£o**: Sistema de scoring e decisÃ£o automatizada
4. **SaÃ­da**: RelatÃ³rios, dashboards e integraÃ§Ã£o com APIs de compliance

### ğŸ“Š Diagrama de Arquitetura Completa

```mermaid
flowchart TD
    %% Data Sources
    subgraph DataSources["ğŸ“Š Fontes de Dados"]
        BQ[(BigQuery<br/>ğŸ“‹ Datasets AML)]
        BDC[Big Data Corp<br/>ğŸ” Sanctions & KYC]
        API_RISK[Risk API<br/>âš ï¸ Monitoring]
        REDIS[(Redis<br/>ğŸ’¾ Cache)]
    end
    
    %% Entry Points
    subgraph EntryPoints["ğŸšª Pontos de Entrada"]
        WEB[Streamlit Dashboard<br/>ğŸ–¥ï¸ Interface Web]
        FLASK[Flask API<br/>ğŸŒ REST Endpoints]
        CELERY[Celery Workers<br/>âš™ï¸ Background Tasks]
    end
    
    %% Core Processing
    subgraph CoreEngine["ğŸ§  Motor de AnÃ¡lise"]
        ALERT_AGENT[Alert Analyser<br/>ğŸš¨ Agente de Alertas]
        SANCTIONS_AGENT[Sanctions Analyser<br/>âš–ï¸ Agente de SanÃ§Ãµes]
        GPT_ENGINE[GPT Analysis Engine<br/>ğŸ¤– IA OpenAI]
        CHUNKING[Chunking System<br/>ğŸ“ Fallback para Tokens]
    end
    
    %% Automated Tasks
    subgraph AutoTasks["â° Tarefas Automatizadas"]
        SHARED_ACCESS[Shared Access ID<br/>ğŸ”‘ GestÃ£o de Acessos]
        INACTIVE_USERS[Inactive Users<br/>ğŸ‘¤ Descredenciamento]
        REANALYSIS[Reanalysis Cases<br/>ğŸ”„ ReanÃ¡lise]
        DAILY_SCAN[Daily Scans<br/>ğŸ“… Varreduras DiÃ¡rias]
    end
    
    %% Analysis Components
    subgraph AnalysisComponents["ğŸ”¬ Componentes de AnÃ¡lise"]
        MERCHANT_REPORT[Merchant Report<br/>ğŸª RelatÃ³rio Comercial]
        CARDHOLDER_REPORT[Cardholder Report<br/>ğŸ’³ RelatÃ³rio Portador]
        PEP_ANALYSIS[PEP Analysis<br/>ğŸ‘‘ Pessoas Expostas]
        BETTING_ANALYSIS[Betting Analysis<br/>ğŸ² Casas de Apostas]
        CONCENTRATION[Concentration Analysis<br/>ğŸ“ˆ ConcentraÃ§Ã£o]
    end
    
    %% Decision Engine
    subgraph DecisionEngine["âš–ï¸ Motor de DecisÃ£o"]
        RISK_SCORING[Risk Scoring<br/>ğŸ“Š PontuaÃ§Ã£o 1-10]
        CLASSIFICATION[Classification<br/>ğŸ·ï¸ Normal/Suspicious/Offense]
        BV_DECISION[Business Validation<br/>âœ… ValidaÃ§Ã£o Empresarial]
        AUTO_DECISION[Auto Decision<br/>ğŸ¤– DecisÃ£o AutomÃ¡tica]
    end
    
    %% Output Systems
    subgraph OutputSystems["ğŸ“¤ Sistemas de SaÃ­da"]
        PAYLOAD_API[Payload to Risk API<br/>ğŸ“¨ Envio de Resultados]
        DASHBOARD[Dashboard Results<br/>ğŸ“Š VisualizaÃ§Ã£o]
        MONITORING[BigQuery Monitoring<br/>ğŸ” MÃ©tricas Performance]
        REPORTS[Compliance Reports<br/>ğŸ“‹ RelatÃ³rios]
    end
    
    %% Main Flow
    WEB --> ALERT_AGENT
    FLASK --> ALERT_AGENT
    CELERY --> ALERT_AGENT
    CELERY --> SANCTIONS_AGENT
    CELERY --> AutoTasks
    
    %% Data Flow
    BQ --> ALERT_AGENT
    BQ --> SANCTIONS_AGENT
    BQ --> AnalysisComponents
    BDC --> SANCTIONS_AGENT
    REDIS --> BQ
    
    %% Alert Analysis Flow
    ALERT_AGENT --> MERCHANT_REPORT
    ALERT_AGENT --> CARDHOLDER_REPORT
    ALERT_AGENT --> PEP_ANALYSIS
    ALERT_AGENT --> BETTING_ANALYSIS
    ALERT_AGENT --> CONCENTRATION
    
    %% AI Processing
    MERCHANT_REPORT --> GPT_ENGINE
    CARDHOLDER_REPORT --> GPT_ENGINE
    PEP_ANALYSIS --> GPT_ENGINE
    BETTING_ANALYSIS --> GPT_ENGINE
    CONCENTRATION --> GPT_ENGINE
    SANCTIONS_AGENT --> GPT_ENGINE
    
    %% Chunking Fallback
    GPT_ENGINE -.->|Token Limit| CHUNKING
    CHUNKING --> GPT_ENGINE
    
    %% Decision Flow
    GPT_ENGINE --> RISK_SCORING
    RISK_SCORING --> CLASSIFICATION
    CLASSIFICATION --> BV_DECISION
    CLASSIFICATION --> AUTO_DECISION
    
    %% Output Flow
    AUTO_DECISION --> PAYLOAD_API
    BV_DECISION --> PAYLOAD_API
    ALERT_AGENT --> DASHBOARD
    SANCTIONS_AGENT --> DASHBOARD
    BQ --> MONITORING
    
    %% Automated Tasks Schedule
    SHARED_ACCESS -->|12h & 16h| PAYLOAD_API
    INACTIVE_USERS -->|8h Daily| PAYLOAD_API
    DAILY_SCAN -->|7:30 Daily| ALERT_AGENT
    SANCTIONS_AGENT -->|18:40 Daily| PAYLOAD_API
    
    %% Styling
    classDef dataSource fill:#e1f5fe,stroke:#01579b,stroke-width:2px,color:#000
    classDef entryPoint fill:#f3e5f5,stroke:#4a148c,stroke-width:2px,color:#000
    classDef coreEngine fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px,color:#000
    classDef autoTask fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#000
    classDef analysis fill:#fce4ec,stroke:#880e4f,stroke-width:2px,color:#000
    classDef decision fill:#fff8e1,stroke:#f57f17,stroke-width:2px,color:#000
    classDef output fill:#e0f2f1,stroke:#00695c,stroke-width:2px,color:#000
    
    class BQ,BDC,API_RISK,REDIS dataSource
    class WEB,FLASK,CELERY entryPoint
    class ALERT_AGENT,SANCTIONS_AGENT,GPT_ENGINE,CHUNKING coreEngine
    class SHARED_ACCESS,INACTIVE_USERS,REANALYSIS,DAILY_SCAN autoTask
    class MERCHANT_REPORT,CARDHOLDER_REPORT,PEP_ANALYSIS,BETTING_ANALYSIS,CONCENTRATION analysis
    class RISK_SCORING,CLASSIFICATION,BV_DECISION,AUTO_DECISION decision
    class PAYLOAD_API,DASHBOARD,MONITORING,REPORTS output
```

## ğŸ› ï¸ Tecnologias

### Backend & Core
- **Python 3.8+**: Linguagem principal
- **Flask 2.3.3**: Framework web para API
- **Streamlit 1.37.0+**: Interface web interativa
- **Celery 5.4.0**: Processamento assÃ­ncrono
- **Redis 4.5.5**: Cache e message broker

### InteligÃªncia Artificial
- **OpenAI GPT-4**: AnÃ¡lise principal de casos
- **OpenAI o3-mini**: DecisÃµes finais e scoring
- **TikToken 0.9.0**: GestÃ£o de tokens

### Dados & Analytics
- **Google Cloud BigQuery 3.12.0**: Data warehouse principal
- **Pandas 2.2.2**: ManipulaÃ§Ã£o de dados
- **Google Cloud APIs**: IntegraÃ§Ã£o com GCP

### Infraestrutura
- **Docker**: ContainerizaÃ§Ã£o
- **Gunicorn 23.0.0+**: WSGI server
- **Structured Logging**: Observabilidade
- **BigQuery Optimizations**: Performance tuning

## âš™ï¸ InstalaÃ§Ã£o

### PrÃ©-requisitos

```bash
# Python 3.8 ou superior
python --version

# Redis Server
redis-server --version

# Google Cloud CLI (opcional)
gcloud --version
```

### 1. Clone o RepositÃ³rio

```bash
git clone https://github.com/your-org/lavandowski.git
cd lavandowski
```

### 2. Ambiente Virtual

```bash
# Criar ambiente virtual
python -m venv venv

# Ativar (Linux/Mac)
source venv/bin/activate

# Ativar (Windows)
venv\Scripts\activate
```

### 3. Instalar DependÃªncias

```bash
pip install -r requirements.txt
```

### 4. Docker (Alternativo)

```bash
# Build da imagem
docker build -t lavandowski .

# Executar container
docker run -p 8080:8080 lavandowski
```

## ğŸ”§ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

Crie um arquivo `.env` na raiz do projeto:

```env
# ğŸ”‘ APIs
OPENAI_API_KEY=sk-your-openai-key
RISK_API_KEY=your-risk-api-key
BIGDATA_TOKEN_HASH=your-bigdata-hash
BIGDATA_TOKEN_ID=your-bigdata-id

# ğŸ—„ï¸ BigQuery
GOOGLE_CLOUD_PROJECT=your-gcp-project
GOOGLE_APPLICATION_CREDENTIALS=path/to/service-account.json

# ğŸ”„ Celery & Redis
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0

# ğŸ” AnÃ¡lise
USER_ID=specific-user-id  # Opcional: para anÃ¡lise especÃ­fica
```

### ConfiguraÃ§Ã£o do Google Cloud

```bash
# AutenticaÃ§Ã£o
gcloud auth application-default login

# Configurar projeto
gcloud config set project your-project-id

# Service Account (produÃ§Ã£o)
export GOOGLE_APPLICATION_CREDENTIALS="path/to/service-account.json"
```

## ğŸ¯ Funcionalidades

### ğŸ–¥ï¸ Dashboard Streamlit

**Acesso**: `http://localhost:8501`

- **VisÃ£o Geral**: MÃ©tricas em tempo real de anÃ¡lises
- **ConfiguraÃ§Ãµes**: PersonalizaÃ§Ã£o de parÃ¢metros de anÃ¡lise
- **Resultados**: VisualizaÃ§Ã£o detalhada de casos analisados
- **ExportaÃ§Ã£o**: RelatÃ³rios para compliance

### ğŸŒ Flask API

**Base URL**: `http://localhost:8080`

- **Health Check**: Monitoramento do sistema
- **Actions Required**: Processamento de aÃ§Ãµes pendentes
- **Reanalysis**: ReanÃ¡lise de casos especÃ­ficos
- **BigQuery Metrics**: MÃ©tricas de performance

### ğŸ“Š Sistema de Scoring

| Score | ClassificaÃ§Ã£o | AÃ§Ã£o |
|-------|---------------|------|
| 1-4   | Baixo Risco   | Normal |
| 5-6   | MÃ©dio Risco   | Normal (monitorar) |
| 7-8   | Alto Risco    | Suspicious Mid |
| 9     | Muito Alto    | Suspicious High |
| 10    | Extremo       | Offense High |

## ğŸ¤– Agentes de AnÃ¡lise

### ğŸš¨ Alert Analyser

**Responsabilidade**: AnÃ¡lise de alertas AML gerados pelo sistema

**Funcionalidades**:
- ClassificaÃ§Ã£o automÃ¡tica de usuÃ¡rios (Merchant vs Cardholder)
- AnÃ¡lise de concentraÃ§Ã£o de transaÃ§Ãµes
- VerificaÃ§Ã£o de casas de apostas
- AnÃ¡lise de PEP (Pessoas Expostas Politicamente)
- Sistema de chunking para casos complexos

**ExecuÃ§Ã£o**: 
- Manual via dashboard
- AutomÃ¡tica diariamente Ã s 07:30

```python
# Exemplo de uso
from app.alert_analyser.app import analyze_user

result = analyze_user(
    user_data={"user_id": 12345, "alert_type": "high_volume"},
    betting_houses=betting_data,
    pep_data=pep_records
)
```

### âš–ï¸ Sanctions Analyser

**Responsabilidade**: AnÃ¡lise de sanÃ§Ãµes do Conselho Nacional de JustiÃ§a

**Funcionalidades**:
- VerificaÃ§Ã£o de sanÃ§Ãµes criminais vs civis
- AnÃ¡lise de correspondÃªncia exata (MatchRate 100)
- DecisÃ£o automÃ¡tica de descredenciamento
- Sistema de chunking para grandes volumes

**ExecuÃ§Ã£o**:
- AutomÃ¡tica diariamente Ã s 18:40

**CritÃ©rios de DecisÃ£o**:
- **Processo Criminal** â†’ Descredenciar (offense/high)
- **Processo Civil** â†’ Manter (normal/low)

```python
# Exemplo de uso
from app.sanctions_analyser.sanctions_app import run_sanctions_analyser

result = run_sanctions_analyser()
# Returns: {"total_alerts": X, "processed": Y, "failed": Z}
```

## â° Tarefas Automatizadas

### ğŸ“… Cronograma de ExecuÃ§Ã£o

| Tarefa | HorÃ¡rio | FrequÃªncia | DescriÃ§Ã£o |
|--------|---------|------------|-----------|
| Alert Analyser | 07:30 | DiÃ¡rio | AnÃ¡lise de novos alertas |
| Inactive Users | 08:00 | DiÃ¡rio | Descredenciamento por inatividade |
| Shared Access ID | 12:00, 16:00 | 2x/dia | GestÃ£o de acessos compartilhados |
| Sanctions Analyser | 18:40 | DiÃ¡rio | AnÃ¡lise de sanÃ§Ãµes |

### ğŸ”‘ Shared Access ID

**Objetivo**: Identificar e terminar acessos compartilhados irregulares

**CritÃ©rios**:
- Mesmo dispositivo usado por mÃºltiplos usuÃ¡rios
- PadrÃµes suspeitos de acesso
- ViolaÃ§Ãµes de polÃ­tica de seguranÃ§a

### ğŸ‘¤ Inactive Users Disaccreditation

**Objetivo**: Descredenciar usuÃ¡rios inativos hÃ¡ mais de 40 dias

**Processo**:
1. Identifica usuÃ¡rios sem contato recente
2. Valida critÃ©rios de elegibilidade
3. Gera payload de descredenciamento
4. Envia para API de compliance

### ğŸ”„ Reanalysis Cases

**Objetivo**: ReanÃ¡lise automÃ¡tica de casos pendentes

**CritÃ©rios**:
- Casos aguardando validaÃ§Ã£o hÃ¡ mais de 5 dias Ãºteis
- Timeout de anÃ¡lises manuais
- MudanÃ§as em critÃ©rios de compliance

## ğŸŒ API Endpoints

### Health & Monitoring

```http
GET /health
```
Status geral do sistema

### Actions Required

```http
POST /actions_required
Authorization: Bearer {token}
Content-Type: application/json

{
  "user_id": 12345,
  "action_type": "business_validation",
  "priority": "high"
}
```

### Reanalysis

```http
POST /reanalysis_case
Authorization: Bearer {token}
Content-Type: application/json

{
  "case_id": "abc123",
  "reason": "new_evidence",
  "analyst_id": 67890
}
```

### BigQuery Metrics

```http
GET /bigquery/metrics
Authorization: Bearer {token}
```

Retorna mÃ©tricas de performance do BigQuery:

```json
{
  "cache_hit_rate_percent": 85.2,
  "average_query_time_ms": 450,
  "slow_queries_count": 3,
  "total_bytes_saved_gb": 127.3,
  "optimization_suggestions": [...]
}
```

```http
POST /bigquery/cache/clear
Authorization: Bearer {token}
```

Limpa cache do BigQuery

```http
GET /bigquery/optimization/suggestions
Authorization: Bearer {token}
```

SugestÃµes de otimizaÃ§Ã£o de queries

## ğŸ“Š Monitoramento

### ğŸ” Performance Metrics

O sistema inclui monitoramento abrangente de performance:

**BigQuery Optimizations**:
- Connection pooling (singleton pattern)
- Cache Redis inteligente
- Query optimization automÃ¡tica
- Alertas para queries lentas

**MÃ©tricas Chave**:
- Taxa de cache hit rate
- Tempo mÃ©dio de resposta
- Bytes processados
- Queries lentas (>10s)

### ğŸ“ˆ Dashboard Analytics

**VisÃ£o Geral**:
- Total de anÃ¡lises realizadas
- Casos suspeitos identificados
- Score mÃ©dio de risco
- Tempo de resposta do sistema

**DistribuiÃ§Ã£o**:
- Alertas por tipo
- NÃ­veis de risco
- TendÃªncia temporal

### ğŸš¨ Alertas AutomÃ¡ticos

- Query > 10 segundos
- Resultados > 100k linhas  
- Bytes processados > 1GB
- Cache hit rate < 50%

## ğŸš€ Uso

### ExecuÃ§Ã£o Local

#### 1. Streamlit Dashboard

```bash
streamlit run app/app.py
```

Acesse: `http://localhost:8501`

#### 2. Flask API

```bash
python app/main.py
```

API disponÃ­vel em: `http://localhost:8080`

#### 3. Celery Workers

```bash
# Terminal 1: Worker
python app/celery_runner.py worker

# Terminal 2: Beat Scheduler
python app/celery_runner.py beat
```

### Docker Compose

```yaml
version: '3.8'
services:
  app:
    build: .
    ports:
      - "8080:8080"
    environment:
      - REDIS_HOST=redis
    depends_on:
      - redis
      
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
      
  worker:
    build: .
    command: python app/celery_runner.py worker
    depends_on:
      - redis
      
  scheduler:
    build: .
    command: python app/celery_runner.py beat
    depends_on:
      - redis
```

### Uso BÃ¡sico

#### AnÃ¡lise Manual via Dashboard

1. Acesse o dashboard Streamlit
2. Configure o perÃ­odo de anÃ¡lise
3. Selecione o tipo de anÃ¡lise (BÃ¡sica/Aprimorada)
4. Clique em "Executar Nova AnÃ¡lise AML"
5. Acompanhe o progresso em tempo real
6. Visualize os resultados detalhados

#### AnÃ¡lise via API

```python
import requests

# Processar aÃ§Ã£o pendente
response = requests.post(
    'http://localhost:8080/actions_required',
    headers={'Authorization': 'Bearer your-token'},
    json={
        'user_id': 12345,
        'action_type': 'review_required'
    }
)

print(response.json())
```

#### AnÃ¡lise ProgramÃ¡tica

```python
from app.alert_analyser.app import analyze_user, fetch_flagged_users

# Buscar usuÃ¡rios sinalizados
flagged_users = fetch_flagged_users()

# Analisar cada usuÃ¡rio
for user_data in flagged_users:
    result = analyze_user(user_data)
    print(f"User {user_data['user_id']}: {result['conclusion']}")
```

## ğŸ‘¥ Desenvolvimento

### ğŸ—ï¸ Estrutura do Projeto

```
lavandowski/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ alert_analyser/         # Analisador de alertas
â”‚   â”‚   â”œâ”€â”€ app.py             # App principal Streamlit
â”‚   â”‚   â”œâ”€â”€ functions.py       # FunÃ§Ãµes de anÃ¡lise
â”‚   â”‚   â”œâ”€â”€ gpt_utils.py       # UtilitÃ¡rios GPT
â”‚   â”‚   â”œâ”€â”€ chunking_system.py # Sistema de chunking
â”‚   â”‚   â””â”€â”€ fetch_data.py      # Queries BigQuery
â”‚   â”œâ”€â”€ sanctions_analyser/    # Analisador de sanÃ§Ãµes
â”‚   â”‚   â”œâ”€â”€ sanctions_app.py   # LÃ³gica principal
â”‚   â”‚   â””â”€â”€ sanctions_fetch_data.py
â”‚   â”œâ”€â”€ automated_tasks/       # Tarefas automatizadas
â”‚   â”‚   â”œâ”€â”€ alert_analyser_task.py
â”‚   â”‚   â”œâ”€â”€ sanctions_analyser_task.py
â”‚   â”‚   â”œâ”€â”€ shared_access_id.py
â”‚   â”‚   â”œâ”€â”€ inactive_users_disaccreditation.py
â”‚   â”‚   â””â”€â”€ reanalysis_case/
â”‚   â”œâ”€â”€ controllers/           # Controladores API
â”‚   â”‚   â”œâ”€â”€ health_controller.py
â”‚   â”‚   â”œâ”€â”€ bigquery_metrics_controller.py
â”‚   â”‚   â””â”€â”€ reanalysis_case_controller.py
â”‚   â”œâ”€â”€ middleware/            # Middleware
â”‚   â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚   â””â”€â”€ bigquery_monitoring.py
â”‚   â”œâ”€â”€ services/              # ServiÃ§os
â”‚   â”‚   â””â”€â”€ celery_app.py
â”‚   â”œâ”€â”€ settings/              # ConfiguraÃ§Ãµes
â”‚   â”‚   â”œâ”€â”€ bigquery.py
â”‚   â”‚   â”œâ”€â”€ bigquery_optimized.py
â”‚   â”‚   â”œâ”€â”€ keys.py
â”‚   â”‚   â””â”€â”€ logger.py
â”‚   â”œâ”€â”€ helpers/               # UtilitÃ¡rios
â”‚   â”œâ”€â”€ app.py                 # App Streamlit principal
â”‚   â”œâ”€â”€ main.py                # App Flask principal
â”‚   â””â”€â”€ routes.py              # Rotas Flask
â”œâ”€â”€ tests/                     # Testes
â”œâ”€â”€ config/                    # ConfiguraÃ§Ãµes
â”œâ”€â”€ requirements.txt           # DependÃªncias
â”œâ”€â”€ Dockerfile                 # Container
â””â”€â”€ README.md                  # DocumentaÃ§Ã£o
```

### ğŸ§ª Testes

```bash
# Executar todos os testes
python -m pytest tests/

# Testes especÃ­ficos
python -m pytest tests/test_alert_analyser.py -v

# Cobertura
python -m pytest --cov=app tests/
```

### ğŸ› Debug

```bash
# Logs detalhados
export LOG_LEVEL=DEBUG
python app/main.py

# Debug Celery
celery -A app.services.celery_app worker --loglevel=debug

# Debug BigQuery
export BIGQUERY_DEBUG=1
```

### ğŸ”§ Contribuindo

1. **Fork** o repositÃ³rio
2. **Clone** seu fork
3. **Crie** uma branch feature (`git checkout -b feature/nova-funcionalidade`)
4. **Commit** suas mudanÃ§as (`git commit -am 'Adiciona nova funcionalidade'`)
5. **Push** para a branch (`git push origin feature/nova-funcionalidade`)
6. **Abra** um Pull Request

### ğŸ“ ConvenÃ§Ãµes

**Commits**:
- `feat:` Nova funcionalidade
- `fix:` CorreÃ§Ã£o de bug
- `docs:` DocumentaÃ§Ã£o
- `style:` FormataÃ§Ã£o
- `refactor:` RefatoraÃ§Ã£o
- `test:` Testes

**Code Style**:
- PEP 8 para Python
- Type hints quando possÃ­vel
- Docstrings para funÃ§Ãµes pÃºblicas
- Logging estruturado

---

## ğŸ“„ LicenÃ§a

Este projeto Ã© propriedade privada da CloudWalk/InfinitePay. Uso restrito conforme acordos internos.

## ğŸ†˜ Suporte

- **DocumentaÃ§Ã£o**: [Wiki Interno](link-interno)
- **Issues**: [GitHub Issues](link-interno)
- **Slack**: #lavandowski-support
- **Email**: aml-team@cloudwalk.io

---

<div align="center">

**ğŸ” Lavandowski AML Platform**  
*Powered by AI â€¢ Built for Compliance â€¢ Made with â¤ï¸*

</div>
